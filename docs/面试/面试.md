# 面试

## 索引失效

**1.最佳左前缀**

（最左优先，在检索数据时从联合索引的最左边开始匹配），例如索引(a,b,c)，只有查询   	(a),(a,b),(a,b,c)会走索引，而(b),(b,c),(c)都不会走索引。

**2.计算、函数会导致索引失效**

```sql
CREATE INDEX idx_name ON student(NAME);
#1.函数导致索引失效，没有走索引
EXPLAIN SELECT SQL_NO_CACHE * FROM student WHERE LEFT(student.name,3) = 'abc';
#索引优化成like，走索引
EXPLAIN SELECT SQL_NO_CACHE * FROM student WHERE student.name LIKE 'abc%';
 
#2.计算导致索引失效
CREATE INDEX idx_sno ON student(stuno);
EXPLAIN SELECT SQL_NO_CACHE id, stuno, NAME FROM student WHERE stuno+1 = 900001;
```

**3.类型转换会导致索引失效**

```sql
CREATE INDEX idx_name ON student(NAME);
 
#1.手动类型转换，通过调用函数，导致索引失效
EXPLAIN SELECT id, stuno, name FROM student WHERE name=CAST(123 as CHAR);
 
#2.自动类型转换导致索引失效。name字段类型是varchar，你赋值成数字它会默认转成字符串导致索引失败
EXPLAIN SELECT SQL_NO_CACHE * FROM student WHERE name=123;
# 索引优化成目标字符串，走索引
EXPLAIN SELECT SQL_NO_CACHE * FROM student WHERE name='123';
```

**4.范围条件右边的列索引失效**

例如（a,b,c）联合索引，查询条件a,b,c，如果b使用了范围查询，那么b右边的c索引失效。

**解决办法：**新建联合索引（a,c,b）或（c,a,b），把需要范围查询的字段放在最后。

范围包括：(<) (<=) (>) (>=) 和 between。

**5.“不等于”导致索引失效**

```sql
CREATE INDEX idx_age_name ON student(age, NAME);
#查所有字段，并且使用“不等于”，索引失效
EXPLAIN SELECT * FROM student WHERE age <> 20;
```

**6.没覆盖索引时，is not null、not like导致索引失效**

**解决方案：**

- **设计数据库的时候就将字段设置为 NOT NULL 约束**
- 将 INT 类型的字段，默认值设置为0。
- 将字符类型的默认值设置为空字符串('')。

**7.左模糊查询导致索引失效**

**8.“OR”前后存在非索引列，导致索引失效**

OR前后的两个条件中的列都是索引时，查询中才使用索引

**9.不同字符集导致索引失败，建议utf8mb4**

**10.隐式类型转换，**会导致索引失效，例如 id字段类型是varchar，我们 where id = 1，这样就会触发隐式类型转换

## spring的常见注释

|                      注释                      |                             说明                             |
| :--------------------------------------------: | :----------------------------------------------------------: |
| @Component、@Controller、@Service、@Repository |                   使用在类上用于实例化bean                   |
|                   @Autowire                    |               使用在字段上用于根据类型依赖注入               |
|                   @Qualifier                   |        结合@Autowire一起使用用于根据名称进行依赖注入         |
|                     @Scope                     |                      标注Bean的作用范围                      |
|                 @Configuration                 | 指定当前类是一个Spring配置类，当创建容器时会从该类上加载注释 |
|                 @ComponentScan                 |            用于指定Spring在初始化容器时要扫描的包            |
|                     @Bean                      |      使用在方法上，标注将该方法返回值存储到spring容器中      |
|                    @Import                     |         使用@Import导入的类会被Spring加载到ioc容器中         |
|  @Aspect、@Before、@After、@Around、@Pointcut  |                     用于切面编程（AOP）                      |

1. **@Configuration**：这个注解用于声明一个类作为配置类，通常用于定义Bean的配置信息。它替代了传统的XML配置方式，提供了更灵活和类型安全的配置选项。
2. **@Bean**：这个注解用于在配置类中定义一个Bean，它告诉Spring这个方法将返回一个对象，该对象应被注册为Spring应用上下文中的一个Bean。
3. **@Autowired**：这个注解用于自动装配Bean。它可以帮助Spring自动注入依赖，减少手动配置的工作量。

## springBoot的注释

1. **@SpringBootApplication**：这是一个复合注解，包含了@Configuration、@EnableAutoConfiguration和@ComponentScan三个注解的功能。它用于声明一个类为Spring Boot应用的主类，是程序的入口点。
2. **@EnableAutoConfiguration**：这个注解告诉Spring Boot根据添加的jar依赖自动配置项目。例如，如果项目中包含了Spring MVC的依赖，Spring Boot会自动配置Spring MVC相关的组件。
3. **@ComponentScan**：这个注解用于告诉Spring在哪些包下进行组件扫描，以便找到并注册Bean。它可以帮助Spring找到并管理项目中的所有组件。

## springMVC常见的注释

1. **@PathVariable**：这个注解用于从URL中提取变量值，并将其绑定到控制器方法的参数上。它常用于RESTful API的路由参数绑定。
2. **@RequestBody**：这个注解用于将HTTP请求体中的数据绑定到控制器方法的参数上。它常用于接收JSON格式的数据。
3. **@ResponseBody**：这个注解用于将控制器方法的返回值转换为HTTP响应的主体。它使得控制器方法返回的对象能够直接作为HTTP响应的内容发送给客户端。
4. **@RestController**：这个注解是@Controller和@ResponseBody的组合，用于声明一个类为RESTful Web服务的控制器。它使得该类中的方法返回的对象能够直接作为JSON格式的数据发送给客户端。

## sql优化

1.对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引（或联合索引）。

2.应尽量避免在 where 子句中使用!=或<>操作符，否则将引擎放弃使用索引而进行全表扫描。

3.应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描

4.应尽量避免在 where 子句中使用 or 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描

5.左模糊查询也将导致全表扫描：

6.in 和 not in 也要慎用，否则会导致全表扫描

7.如果在 where 子句中使用@参数，也会导致全表扫描。

8.应尽量避免在 where 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描

9.应尽量避免在where子句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描

10.不要在 where 子句中的“=”左边进行函数、算术运算或其他表达式运算，否则系统将可能无法正确使用索引。

11.在使用索引字段作为条件时，如果该索引是复合索引，那么必须使用到该索引中的第一个字段作为条件时才能保证系统使用该索引，否则该索引将不会被使用，并且应尽可能的让字段顺序与索引顺序相一致。

12.不要写一些没有意义的查询

13.很多时候用 exists 代替 in 是一个好的选择

14.并不是所有索引对查询都有效

15.索引并不是越多越好

16.应尽可能的避免更新 clustered 索引数据列

17.尽量使用数字型字段

18.尽可能的使用 varchar/nvarchar 代替 char/nchar

19.任何地方都不要使用 `select * from t `，用具体的字段列表代替“*”，不要返回用不到的任何字段。

20.尽量使用表变量来代替临时表。如果表变量包含大量数据，请注意索引非常有限（只有主键索引）。

21.避免频繁创建和删除临时表，以减少系统表资源的消耗。

22.临时表并不是不可使用，适当地使用它们可以使某些例程更有效

23.在新建临时表时，如果一次性插入数据量很大，那么可以使用 select into 代替 create table，避免造成大量 log ，以提高速度

24.如果使用到了临时表，在存储过程的最后务必将所有的临时表显式删除，先 truncate table ，然后 drop table ，这样可以避免系统表的较长时间锁定。

25.尽量避免使用游标，因为游标的效率较差，如果游标操作的数据超过1万行，那么就应该考虑改写。

26.使用基于游标的方法或临时表方法之前，应先寻找基于集的解决方案来解决问题，基于集的方法通常更有效。

27.与临时表一样，游标并不是不可使用

28.在所有的存储过程和触发器的开始处设置 SET NOCOUNT ON ，在结束时设置 SET NOCOUNT OFF 。

29.尽量避免向客户端返回大数据量，若数据量过大，应该考虑相应需求是否合理。

30.尽量避免大事务操作，提高系统并发能力。



## 数据库优化

1.**是否请求了不需要的数据**

2.**是否扫描了额外的记录**

3.**一个复杂查询OR多个简单查询**

4.**切分查询**

5.**分解关联查询**

```sql
select * from teacher t
join student s on t.id = s.t_id
join class c on t.id = c.t_id
where t.name = 'Li';
-- 拆分后
select * from teacher t where t.name = 'Li';
select * from student s where s.id = 12;
select * from class c where c.id in (13,45,65)
```



## ReentrantLock 和synchronized区别

1.**灵活性**

- `ReentrantLock` 提供了更多的灵活性，例如可以指定尝试获取锁的最大等待时间和是否可中断等。

2.**中断性**:

- `ReentrantLock` 允许线程在等待锁的过程中被中断（通过 `lockInterruptibly()` 方法），而 `synchronized` 不支持。

3.**公平性**

- `ReentrantLock` 允许你选择是否要公平地分配锁（`true` 或 `false` 作为构造参数），这意味着如果设置为公平锁，锁将按照请求锁的顺序来分配。

4.**锁的实现**

- `ReentrantLock` 是显式锁（Explicit Lock），需要程序员手动获取和释放。
- `synchronized` 是隐式锁，它由编译器和运行时来保证正确的获取和释放。

5.**使用范围**

- `ReentrantLock` 可以用于方法之外的场景，如同步代码块或某个特定的代码段。
- `synchronized` 主要用于同步方法或同步代码块。

## Lock和synchronized的区别

**`Lock`：** 是Java中的接口，可重入锁、悲观锁、独占锁、互斥锁、同步锁。

- 1.Lock需要手动获取锁和释放锁。就好比自动挡和手动挡的区别
- 2.Lock 是一个接口，而 synchronized 是 Java 中的关键字， synchronized 是内置的语言实现。
- 3.synchronized 在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；而 Lock 在发生异常时，如果没有主动通过 unLock()去释放锁，则很可能造成死锁现象，因此使用 Lock 时需要在 finally 块中释放锁。
- 4.Lock 可以让等待锁的线程响应中断，而 synchronized 却不行，使用 synchronized 时，等待的线程会一直等待下去，不能够响应中断。
- 5.通过 Lock 可以知道有没有成功获取锁，而 synchronized 却无法办到。
- 6.Lock 可以通过实现读写锁提高多个线程进行读操作的效率。

**synchronized的优势：**

- 足够清晰简单，只需要基础的同步功能时，用synchronized。
- Lock应该确保在finally块中释放锁。如果使用synchronized，JVM确保即使出现异常，锁也能被自动释放。
- 使用Lock时，Java虚拟机很难得知哪些锁对象是由特定线程锁持有的。

## java的锁

1.**乐观锁**

**是一种乐观思想**，假定当前环境是读多写少，遇到并发写的概率比较低，读数据时认为别的线程不会正在进行修改（所以没有上锁）。写数据时，判断当前 与期望值是否相同，如果相同则进行更新（更新期间加锁，保证是原子性的）。

2.**悲观锁**

**是一种悲观思想**，即认为写多读少，遇到并发写的可能性高，每次去拿数据的时候都认为其他线程会修改，所以每次读写数据都会认为其他线程会修改，所以每次读写数据时都会上锁。其他线程想要读写这个数据时，会被这个线程block，直到这个线程释放锁然后其他线程获取到锁。

3.**读写锁**

通过`ReentrantReadWriteLock`类来实现。为了提高性能， Java 提供了读写锁，在读的地方使用读锁，在写的地方使用写锁，灵活控制，如果没有写锁的情况下，读是无阻塞的，在一定程度上提高了程序的执行效率。读写锁分为读锁和写锁，多个读锁不互斥，读锁与写锁互斥，这是由 jvm 自己控制的。

**读锁：** 允许多个线程获取读锁，同时访问同一个资源。

**写锁：** 只允许一个线程获取写锁，不允许同时访问同一个资源。

```java
/**
* 创建一个读写锁
* 它是一个读写融为一体的锁，在使用的时候，需要转换
*/
private ReentrantReadWriteLock rwLock = new ReentrantReadWriteLock();

// 获取读锁
rwLock.readLock().lock();

// 释放读锁
rwLock.readLock().unlock();
// 创建一个写锁
rwLock.writeLock().lock();

// 写锁 释放
rwLock.writeLock().unlock();
```

4.**公平锁**

多个线程按照申请锁的顺序来获取锁。在并发环境中，每个线程会先查看此锁维护的等待队列，如果当前等待队列为空，则占有锁，如果等待队列不为空，则加入到等待队列的末尾，按照FIFO的原则从队列中拿到线程，然后占有锁。

5.**非公平锁**

 线程尝试获取锁，如果获取不到，则再采用公平锁的方式。多个线程获取锁的顺序，不是按照先到先得的顺序，有可能后申请锁的线程比先申请的线程优先获取锁。

**优点：** 非公平锁的性能高于公平锁。

**缺点：** 有可能造成线程饥饿（某个线程很长一段时间获取不到锁）

**Java中的非公平锁：**synchronized是非公平锁，ReentrantLock通过构造函数指定该锁是公平的还是非公平的，默认是非公平的。

6.**共享锁**

 可以有多个线程获取读锁，以共享的方式持有锁。和乐观锁、读写锁同义。

**Java中用到的共享锁：** `ReentrantReadWriteLock`。

7.**独占锁**

只能有一个线程获取锁，以独占的方式持有锁。和悲观锁、互斥锁同义。

**Java中用到的独占锁：** synchronized，ReentrantLock

8.**重量级锁**

`synchronized`是通过对象内部的一个叫做监视器锁（`monitor`）来实现的，监视器锁本身依赖底层的操作系统的 `Mutex Lock`来实现。操作系统实现线程的切换需要从用户态切换到核心态，成本非常高。这种依赖于操作系统 `Mutex Lock`来实现的锁称为重量级锁。为了优化`synchonized`，引入了`轻量级锁`，`偏向锁`。

**Java中的重量级锁：** synchronized

## redis缓存穿透

**描述：**指查询一个数据库一定不存在的数据。正常的使用缓存流程大致是，数据查询先进行缓存查询，如果 key 不存在或者 key 已经过期，再对数据库进行查询，并把查询到的对象，放进缓存。如果数据库查询对象为空，则不放进缓存。但是这种方法存在一个问题，比如我传一个用户 id 为 - 1，这个用户 id 在缓存里面是肯定不存在的，所以会去数据库里面查询，如果有搞事情的人，大批量请求并传用户 id 为 - 1，那就和没用 redis 一样，导致数据库压力过大而崩溃。

**解决方法：**

**方法一：**在接口层增加校验，不合法的参数直接返回。不相信任务调用方，根据自己提供的 API 接口规范来，作为被调用方，要考虑可能任何的参数传值。

**方法二：**在缓存查不到，DB 中也没有的情况，可以将对应的 key 的 value 写为 null，或者其他特殊值写入缓存，同时将过期失效时间设置短一点，以免影响正常情况。这样是可以防止反复用同一个 ID 来暴力攻击。

**方法三：**正常用户是不会这样暴力功击，只有是恶意者才会这样做，可以在网关 NG 作一个配置项，为每一个 IP 设置访问阈值。

**方法四：**高级用户布隆过滤器（Bloom Filter), 这个也能很好地防止缓存穿透。原理就是利用高效的数据结构和算法快速判断出你这个 Key 是否在 DB 中存在，不存在你 return 就好了，存在你就去查了 DB 刷新 KV 再 return。

```
https://www.bilibili.com/video/BV1zK4y1h7pA/?spm_id_from=333.880.my_history.page.click&vd_source=87ca7d166405133710d8da17bacab1ea
```



## redis缓存雪崩

**在同一个时间，缓存大批量的失效，然后所有请求都打到 DB 数据库，导致 DB 数据库直接扛不住崩了。**比如，电商首页缓存，如果首页的 key 全部都在某一时刻失效，刚好在那一时刻有秒杀活动，那这样的话就所有的请求都被打到了 DB。并发大的情况下 DB 必然扛不住，没有其他降级之类的方案的话，DBA 也只能重启 DB，但是这样又会被新的流量搞挂。

#### **解决方法–缓存雪崩**

批量往 redis 存数据的时候，把每个 key 的失效时间加上个随机数，比如 1-5 分钟随机，这样的话就能保证数据不会在同一个时间大面积失效。

## redis缓存击穿

缓存击穿跟缓存雪崩有些类似，雪崩是大面积缓存失效，导致数据库崩溃，而缓存击穿是一个 key 是热点，不停地扛住大并发请求，全都集中访问此 key, 而当此 key 过期瞬间，持续的大并发就击穿缓存，全都打在 DB 上。就又引发雪崩的问题。

**解决方法–缓存击穿**
**方法一：**把这个热点 key 设置为永久有效。

**方法二：**使用互斥锁，这是比较常用的方法，简单地来说，就是在缓存失效的时候（判断拿出来的值为空），不是立即去查询数据库，而是先使用缓存工具的某些带成功操作返回值的操作（比如 Redis 的 SETNX 或者 Memcache 的 ADD）去 set 一个 mutex key，当操作返回成功时，再进行查询数据库的操作并回设缓存；否则，就重试整个 get 缓存的方法。

## redis数据删除策略

**1.惰性删除**：设置该key过期时间后，我们不去管它，当需要该key时，我们在检查其是否过期，如果过期，我们就删除它返回key

​	**优点**：对cpu有好，只会在使用该key时才会进行过期检查对于很多用不到的key不用 浪费时间进行过期检查

​	**缺点**：对内存不友好，如果一个key过期，但是一直没有被使用，那么该key就会一直存在在内存中，内存永远不会被释放

**2.定期删除**：每隔一段时间，我们就对一些key进行检查，删除里面过期的key(从一定数量的数据库中取出一定数量的随机key进行检查，并删除其中的过期key)。
	**定期清理有两种模式**
		**SLOW模式**是定时任务，执行频率默认为10hz，每次不超过25ms，以通过修改配置文件redis.conf的hz 选项来调整这个次数
		**FAST模式**执行频率不固定，但两次间隔不低于2ms，每次耗时不超过1ms
		**优点**:可以通过限制删除操作执行的时减少删除操作对 CPU 的影响。另外定期删除，也能有效释放过期数据占用的内存。
		**缺点**:难以确定删除操作执行的时长和删除频率
		**Redis的过期删除策略**:惰性删除+定期删除两种策略进行配合使用

## 分布式锁

**1.setNX**(不推荐)

SETNX命令的工作过程是去set一个不存在的key，多个线程去设置同一个key只会有一个线程设置成功，设置成功的的线程拿到锁。

```java
Boolean flag = redisTemplate.opsForValue().setIfAbsent(key,vaue);
```

**缺点：**1.首先是不原子性的（要想进行原子性操作得用lua脚本）2.不支持可重入

**2.Redisson分布式锁**

Redisson 是封装了 lua 脚本，保证获取、判断、加锁操作的原子性，一个客户端要加锁，它首先会根据[hash](https://so.csdn.net/so/search?q=hash&spm=1001.2101.3001.7020)节点选择一台机器，这里注意仅仅只是选择一台机器，紧接着就会发送一段封装好的 lua 脚本到 redis 上。

```java
@Autowired
RedissionClient redissionClient;

RLock lock = redissionClient.getLock("coursequerylock:"+id);
//释放锁
lock.lock;
try{
    //执行方法
    ...
}finally{
    //释放锁
    lock.unlock();
}
```

**锁续期机制**

Redisson 提供了一个续期机制，只要客户端 1 一旦加锁成功，就会启动一个 Watch Dog (看门狗)

```
注意：

1、参数 leaseTime 必须是 -1 才会开启 Watch Dog 机制，也就是如果你想开启 Watch Dog 机制必须使用默认的加锁时间为 30s。如果你自定义释放时间，超过这个时间锁就会自定释放，并不会延长

2、这里有个问题，如果服务宕机了，Watch Dog 机制后台定时任务线程也就没有了，此时就不会延长 key 的过期时间，到了 30s 之后就会自动过期，其他线程就可以获取到锁
```

**总结**

1、Redisson 通过 Watch Dog 机制很好的解决了锁的续期问题

2、Redisson 基于 Redis 性能很高，适合对性能要求高的场景

3、Redisson 实现分布式可重入锁，比原生的 SET mylock userId NX PX milliseconds + lua 实现的效果更好些，虽然基本原理都一样，但是它帮我们封装了内部的执行细节(官方封装更严谨)

4、在等待申请锁资源占用上也做了一些优化，减少了无效的锁申请，提升了资源的利用率

5、Redisson 的获取锁默认是非公平的(随机抢锁)，可以使用 getFairLock() 获取公平锁对象（线程将以其请求的时间顺序获取锁），如下：

```java
//公平锁，保证 Redisson 客户端线程将以其请求的顺序获得锁
RLock fairLock = redissonClient.getFairLock("fairLock");
```

## 什么情况下事务会失效

1.在方法中捕获异常没有抛出

2.@Transaction标记的方法不是public

3.抛出的异常与事务指定异常不一致，默认的异常是RuntimeExecption

4.内部调用而不是代理对象调用

5.数据不支持事务。比如mysql 的 MYISAM

6.spring传播行为导致事务失效

## mysql中InnoDB和myISAM存储引擎的区别

|            | InnoDB |   myISAM   |
| :--------: | :----: | :--------: |
|  事务处理  |   √    |            |
| 表锁及行锁 |   √    | 仅支持表锁 |
|  外键约束  |   √    |            |
|  索引结构  |   B+   |     B      |
|  崩溃恢复  |   √    |            |

## hashMap

hashmap是通过键值对key-value的形式存放，并允许有null和null值，key的null值只能有一个，他是无序的，针对单线程设计的是非线程安全的

**put（）方法：**调用hashcode计算出key的hash值并通过哈希表函数将之转换为下标，之后通过equal进行比较，如果相等更新value值，不相等直接插入。在put中如果插入的个数超过了数组长度×负载因子，就会将数组扩容为之前的两倍，链表长度长度超过默认为8的阈值就会转换为红黑树

**get（）方法：**通过调用hashCode计算出哈希值，根据下标去遍历链表，再进行equals比较，之后再把数据返回给用户

## 简述是nginx？

Nginx是一个 轻量级/高性能的反向代理Web服务器，用于 HTTP、HTTPS、SMTP、POP3 和 IMAP协议。他实现非常高效的**反向代理**、**负载平衡**，他可以处理2-3万并发连接数，官方监测能支持5万并发，现在中国使用nginx网站用户有很多，例如:新浪、网易、腾讯等

## nginx负载均衡的5种策略

1. `round_robin`：轮询（默认）。
2. `least_conn`：最少连接。
3. `ip_hash`：根据客户端IP地址。
4. `random`：随机。 
5. `random two`：随机两次尝试，然后回到轮询。

## 事务的传播

事务的传播行为，主要分为三种类型，分别是：**支持当前事务**、**不支持当前事务**、**嵌套事务**

**1 支持当前事务**

**REQUIRED**：默认的事务传播级别，表示如果当前方法已在事务内，该方法就在当前事务中执行，否则，开启一个新的事务并在其上下文中执行。（默认的事务传播行为，保证多个嵌套的事务方法在同一个事务内执行，并且同时提交，或者出现异常时，同时回滚。）

**SUPPORTED**：当前方法在事务内，则在其上下文中执行该方法，否则，开启一个新的事务。（当外层方法A存在事务，方法B加入到当前事务中，以事务的方式执行。）

**MANDATORY**：必须在事务中执行，否则，将抛出异常。（必须在事务中执行）

**2 不支持当前事务**

**REQUIRES_NEW**：无论当前是否有事务上下文，都会开启一个事务 。如果已经有一个事务在执行 ，则正在执行的事务将被挂起 ，新开启的事务会被执行。（每次都开启一 个新的事务。）

事务之间相互独立，互不干扰。

**NOT_SUPPORTED**：不支持事务，如果当前存在事务上下文，则挂起当前事务，然后以非事务的方式执行。（不支持事务。）

**NEVER**：不能在事务中执行，如果当前存在事务上下文，则抛出异常。（不支持事务）

**3 嵌套事务**

**NESTED**：嵌套事务，如果当前已存在一个事务的上下文中，则在嵌套事务中执行，如果抛异常，则回滚嵌套事务，而不影响其他事务的操作。

- 如果外层方法A不存在事务，内层方法B的规则与REQUIRED 一致。
- 如果外层方法A存在事务，内层方法B做为外层方法A事务的子事务执行，两个方法是一起提交，但子事务是独立回滚。
  内层方法B抛出异常，则会回滚方法B的所有操作，但不影响外层事务方法A。（方法A需要try-catch子事务，避免异常传递到父层事务）
  外层方法A回滚，则内层方法B也会回滚。
- 该传播性的特点是可以保存状态点，当回滚时，只会回滚到某一个状态点，保证了子事务之间的独立性，避免嵌套事务的全局回滚。

## AOP

 AOP（面向切面编程）是一种编程范式，用于将横切关注点与核心业务逻辑分离开来。

**AOP由以下几个部分组成：**

1.连接点（JoinPoint）:程序执行过程中的任意位置，粒度为执行方法、抛出异常、设置变量等

2、切入点（Pointcut）:匹配连接点的式子（一个切入点可以只描述一个具体方法，也可以匹配多个方法）

3、通知（Advice）：在切入点处执行的操作，也就是共性的功能

4、通知类：定义通知的类，（包含多个不同的通知）

5、切面（Aspect）：描述通知与切入点的对应关系。（使用@Aspect注解标识）

6、目标对象：原始功能去掉共性功能对应的类产生的对象，这种对象无法直接完成最终工作的，也是我们要添加共性功能的对象。

7、代理实现：目标对象无法直接完成工作，需要对其进行功能回填，通过原始对象的代理对象实现（一般我们自定义一个接口，将接口加入到目标对象（方法）中，使切入点对映接口）

**导入依赖**

```xml
<!--springboot集成Aop-->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-aop</artifactId>
</dependency>
```

**定义一个切面类**，在切面类中实现我们的AOP增强操作。加入@Aspect注解，定义为切面类，并在切面类中，实现通知和切入点的实现，并绑定它们之间的关系。

```java
@Component
@Aspect   //切面类
```

**切入点表达式**

- `execution`：匹配方法的执行。
- `within`：匹配在特定类或包中的所有方法。
- `args`：匹配具有特定参数类型的方法。
- `target`：匹配特定目标对象的方法。
- `this`和`bean`：匹配当前代理对象或特定Spring bean的方法。

```java
	/**
     * aop：切面，切入点，通知
     * 切面：泛指交叉的业务逻辑。比如日志记录，事务管理就是一个切面
     * 切入点：切入的地方
     * 通知：对代码增强的
     * 切入点
     */
//       ("execution(任意返回值 com.sky.mapper下的任意类的任意方法（任意参数）&&方法上有AutoFill的注释的）“）
    @Pointcut("execution(* com.sky.mapper.*.*(..)) && @annotation(com.sky.annotation.AutoFill)")
	public void autoFillPointCut(){}
	/**
     * 前置通知，在通知中进行公共字段的赋值
     */
    @Before("autoFillPointCut()")
    public void autoFill(JoinPoint joinPoint){
        //前置实现代码
        ...
    }

	@After("autoFillPointCut()")
	public void afterWay(JoinPoint joinPoint){
        //后置实现代码
        ...
    }
 	@Around("autoFillPointCut()")
    public Object aroundWay(ProceedingJoinPoint pjp) throws Throwable {
        //前置执行
        ...
        // 执行原方法
        Object result = pjp.proceed();
        
        //后置执行
        ...
        return null;
    }

    

```

**aop通知方式**

- `@Before`：在方法执行之前执行。
- `@After`：在方法执行之后执行，无论方法是否成功。
- `@AfterReturning`：在方法成功返回之后执行。
- `@AfterThrowing`：在方法抛出异常之后执行。
- `@Around`：在方法执行前后都执行，可以完全控制方法的执行过程。

**统一赋值的操作示例：**

```java
	@Target(ElementType.METHOD)
	@Retention(RetentionPolicy.RUNTIME)
	public @interface AutoFill {
    	//数据库操作类型：UPDATE INSERT
    	OperationType value();
	}

	@Before("autoFillPointCut()")
    public void autoFill(JoinPoint joinPoint){
        log.info("开始进行公共字段填充。。。");
//        System.out.println("------------------------------");
        log.info("joinPoint"+joinPoint.toString());

        //获取到当前被拦截方法上的数据库操作类型
        MethodSignature signature = (MethodSignature) joinPoint.getSignature();//获取方法签名对象
        AutoFill annotation = signature.getMethod().getAnnotation(AutoFill.class);//获取方法上的额注解对象
        OperationType operationType = annotation.value();//获取数据库操作类型 UPDATE INSERT
        //获取到当前被拦截的方法的参数--实体对象
        Object[] args = joinPoint.getArgs();
        if (args == null || args.length ==0) return; //判断数据中的对象是否存在


        Object entity = args[0];//默认取第一个参数

        //准备赋值的数据
        LocalDateTime now = LocalDateTime.now();
        Long currentId = BaseContext.getCurrentId();

        //根据当前不同的操作类型，为对应的属性通过反射来赋值
        if (operationType == OperationType.INSERT){
            //为4个公共字段赋值
            try {
                //反射获取类方法
                Method setCreateTime = entity.getClass().getDeclaredMethod(AutoFillConstant.SET_CREATE_TIME, LocalDateTime.class);
                Method setCreateUser = entity.getClass().getDeclaredMethod(AutoFillConstant.SET_CREATE_USER, Long.class);
                Method setUpdateTime = entity.getClass().getDeclaredMethod(AutoFillConstant.SET_UPDATE_TIME, LocalDateTime.class);
                Method setUpdateUser = entity.getClass().getDeclaredMethod(AutoFillConstant.SET_UPDATE_USER, Long.class);

                //数据赋值
                setCreateTime.invoke(entity,now);
                setCreateUser.invoke(entity,currentId);
                setUpdateTime.invoke(entity,now);
                setUpdateUser.invoke(entity,currentId);

            } catch (Exception e) {
                e.printStackTrace();
            }


        }else if (operationType == OperationType.UPDATE){
            //为2个公共字段赋值
            try {
                //反射获取类方法
                Method setUpdateTime = entity.getClass().getDeclaredMethod(AutoFillConstant.SET_UPDATE_TIME, LocalDateTime.class);
                Method setUpdateUser = entity.getClass().getDeclaredMethod(AutoFillConstant.SET_UPDATE_USER, Long.class);

                //数据赋值
                setUpdateTime.invoke(entity,now);
                setUpdateUser.invoke(entity,currentId);

            } catch (Exception e) {
                e.printStackTrace();
            }
        }
    }
```

# @PostMapping和@GetMapping的区别

1.参数传递方式：@GetMapping通常是从URL中获取参数，@PostMapping是从请求体中获取参数

2.安全性：post请求将数据放在请求体中，get是将请求数据放在url中，所以post比get更安全，尽量不要用get请求处理敏感数据

3.RESTful设计中，getMapping一般是查询数据请求，postMapping用作创建或者更新数据

4.参数限制：get请求的参数没有长度限制，但是url长度有限制，所以get请求的参数太长后端可能获取不全所有的参数



## redis持久化

将redis数据存储到系统磁盘上，防止服务进行重启之后导致数据丢失

**持久化方式：**RDB和AOF

**快照方式RDB（redis DateBase）：** 将某一时刻的redis的内存数据，以二进制的方式写入磁盘，速度快，会丢失数据

**文件追加方式AOF（Append only）**

## CAP定理

- Consistency（一致性）
- Availability（可用性）
- Partition tolerance（分区容错性）

## 分布式事务

#### **seata的XA模式**（cp模式（强一致性））

**RM一阶段的工作：**

1.注册分支事务到TC

2.执行分支业务sql但不提交

3.报告执行状态到TC

**TC二阶段的工作：**

TC检测各个分支事务执行状态

a.如果成功，通知所有RM提交事务

b.如果失败，通知所有RM回滚事务

**RM二阶段的工作**

接收TC指令，提交或者回滚事务 

# 线程池应该设置多少核心线程数

**cpu密集型**：cpu核心数+1

I**O密集型**：cpu核心数*2

**混合型任务**：

- 需要根据实际测试调整
- 可以先设置为CPU核心数的2-3倍，然后根据监控调整

## nacos隔离机制

nacos通过namespace实现环境隔离

## 循环依赖

![image-20250401111523205](.\jpgpng\image-20250401111523205.png)

两个或者两个以上的bean互相持有对方，最终行程闭环

**解决方式**：三级缓存

​	一级缓存：单例池，缓存已经经历了完整的生命周期，已经初始化完成的bean对象

​	二级缓存：缓存早期的bean对象（生命周期还没有走完）

​	三级缓存：缓存的是ObjectFactory，表示对象工厂，用来创建某个对象

## CPU飙升100%如何排查

**解决方法论**：

​	1.查看占用cpu最高的TOP N 线程

​	2.查看TOP N线程堆栈信息

​	3.根据代码针对性解决问题

**使用jstack解决CPU 100%问题**：

​	1.查看占用cpu最高的TOP N 线程---top -Hp 29400

​	2.查看TOP N线程堆栈信息---jstack -l 29440

​	3.根据代码针对性解决问题

**使用arthas解决CPU 100%问题**：

​	1.查看占用cpu最高的TOP N 线程 --- dashboard

​	2.查看TOP N线程堆栈信息 --- thread -n 3

​	3.根据代码针对性解决问题

